{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a-Hnx_4qesFq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16bbfb6-770b-4588-cf05-b261cf064caa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path =  \"/content/drive/MyDrive/final_data.csv\"\n",
        "\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FLSAhUNhCAa",
        "outputId": "ce277e2e-07d7-41d2-aaf2-cf1692fce4a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      dim_0     dim_1     dim_2     dim_3     dim_4     dim_5     dim_6  \\\n",
            "0 -0.005985  0.015627  0.007076  0.006575  0.014297  0.007125 -0.000785   \n",
            "1  0.021908 -0.084995 -0.011690 -0.048774 -0.052874 -0.018173  0.058139   \n",
            "2  0.014475 -0.069880 -0.003023  0.022581 -0.021881  0.012437  0.103112   \n",
            "3 -0.019438 -0.003835 -0.027385  0.019167 -0.001544  0.027654 -0.007453   \n",
            "4  0.000870  0.018253  0.025201 -0.015667  0.002589 -0.026993 -0.012401   \n",
            "\n",
            "      dim_7     dim_8     dim_9  ...   dim_298   dim_299  Label     chunk  \\\n",
            "0 -0.009658 -0.001066 -0.043356  ...  0.008799 -0.023102      1       JJP   \n",
            "1 -0.065300 -0.007800 -0.011115  ...  0.021349  0.001630      0       VGF   \n",
            "2 -0.104538 -0.024584  0.046685  ... -0.050404 -0.116184      0       CCP   \n",
            "3 -0.041042 -0.011774 -0.011934  ...  0.024064 -0.017355      1        NP   \n",
            "4 -0.034212  0.000570  0.025318  ...  0.004674  0.013638      0  NULL__NP   \n",
            "\n",
            "   postposition  head-POS  dependency-head  dependency       srl  predicate  \n",
            "0             0       adj              VGF         k1s  ARG2-ATR      VGF.1  \n",
            "1            है         v                0        root         0          0  \n",
            "2             0       avy         NULL__NP          rs         0          0  \n",
            "3          0_को         n             VGNF         k7t  ARGM-TMP       VGNF  \n",
            "4             0         0                0        root         0          0  \n",
            "\n",
            "[5 rows x 308 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET**\n",
        "- For the dataset we have retrieved the dataset from a paper source, the dataset contains the word embeddings of 300 dimension\n",
        "- Along with this the dataset also contain the columms with posposition, head-POS , srl , predicate and etc\n",
        "- But out of these we just need the embeddings for the classification and the label would the be SRL\n",
        "- So for the preparation of the data, we just use these attributes as for this project"
      ],
      "metadata": {
        "id": "qEO4wGyZF-b_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = data['srl']\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrzkic_6jRiP",
        "outputId": "e0924705-532a-49c1-9ce2-d12da0cdaa7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        ARG2-ATR\n",
            "1               0\n",
            "2               0\n",
            "3        ARGM-TMP\n",
            "4               0\n",
            "           ...   \n",
            "14541           0\n",
            "14542        ARG1\n",
            "14543           0\n",
            "14544           0\n",
            "14545           0\n",
            "Name: srl, Length: 14546, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "def encode_labels(data):\n",
        "    le = LabelEncoder()\n",
        "\n",
        "    le.fit(data)\n",
        "\n",
        "    encoded_data = le.transform(data)\n",
        "\n",
        "    uniq_labels = list(le.classes_)\n",
        "\n",
        "    return encoded_data, uniq_labels, le\n",
        "\n",
        "encoded_labels, uniq_labels, decoder = encode_labels(labels)\n",
        "data['srl'] = encoded_labels\n",
        "print(uniq_labels)\n",
        "# print(len(encoded_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83JkXM_sj5a0",
        "outputId": "8e60b604-2544-4cfc-e701-65018678875d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0', 'ARG-UNDEF', 'ARG0', 'ARG1', 'ARG2', 'ARG2-ATR', 'ARG2-GOL', 'ARG2-LOC', 'ARG2-SOU', 'ARG3', 'ARGM-ADV', 'ARGM-CAU', 'ARGM-DIR', 'ARGM-DIS', 'ARGM-EXT', 'ARGM-LOC', 'ARGM-MNR', 'ARGM-MNS', 'ARGM-MOD', 'ARGM-NEG', 'ARGM-PRP', 'ARGM-PRX', 'ARGM-TMP']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LABEL ENCODER**\n",
        "- For the labels we need to encode them, so using the LabelEncoder() we convert them into numerical values and store the encoded data.\n",
        "- The Fit(data) trains it on the data and then retrieves the unique labels after encoding.\n",
        "- Now instead of storing the labels directly we store them as the encoded form"
      ],
      "metadata": {
        "id": "icnQRH_EMPOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "redundant_cols = ['Label', 'chunk', 'postposition', 'head-POS', 'dependency-head', 'dependency', 'srl', 'predicate']\n",
        "#dropping all the unnecessary columns from the file\n",
        "x = data.drop(redundant_cols,axis = 1)\n",
        "\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiayKL9Zs45P",
        "outputId": "555bc350-78bd-441d-8677-056bfda7773c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14546, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train.shape,X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CqRyMKIrMIs",
        "outputId": "8699543f-c252-4693-8ed6-7507b4b98e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11636, 300) (2910, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(max_iter = 2000)\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "print(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYs8en46rWYq",
        "outputId": "e111ff5a-7e74-4b09-df3e-11d3f9d41432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SRL USING THE LOGISTIC REGRESSION\n",
        "- Here we have used the logistic regression for the classification\n",
        "- We give the train data and the train labels for the fitting and then test the model upon the testing data and get the predictions.\n",
        "- And the predictions we got we compare it with the actaul results and give out the accuracy\n",
        "\n",
        "- In this case we get an accuracy of 62%"
      ],
      "metadata": {
        "id": "xbiw4VeDRUv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_labels = decoder.inverse_transform(y_pred)\n",
        "y_test_labels = decoder.inverse_transform(y_test)"
      ],
      "metadata": {
        "id": "8I_j6_UhvXSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test_labels, y_pred_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVZ_E_Cdxb62",
        "outputId": "1905a536-e402-4773-d699-e870140847bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.94      0.76      1755\n",
            "        ARG0       0.51      0.16      0.25       201\n",
            "        ARG1       0.57      0.28      0.37       432\n",
            "        ARG2       0.00      0.00      0.00        38\n",
            "    ARG2-ATR       0.29      0.03      0.06        63\n",
            "    ARG2-GOL       0.00      0.00      0.00         9\n",
            "    ARG2-LOC       0.00      0.00      0.00         6\n",
            "    ARG2-SOU       0.00      0.00      0.00         5\n",
            "        ARG3       0.00      0.00      0.00         2\n",
            "    ARGM-ADV       0.00      0.00      0.00        22\n",
            "    ARGM-CAU       0.50      0.08      0.13        13\n",
            "    ARGM-DIR       0.00      0.00      0.00         3\n",
            "    ARGM-DIS       0.00      0.00      0.00        25\n",
            "    ARGM-EXT       0.00      0.00      0.00        17\n",
            "    ARGM-LOC       0.33      0.04      0.07       133\n",
            "    ARGM-MNR       0.67      0.02      0.04        91\n",
            "    ARGM-MNS       0.00      0.00      0.00         7\n",
            "    ARGM-MOD       0.00      0.00      0.00         1\n",
            "    ARGM-PRP       0.00      0.00      0.00        25\n",
            "    ARGM-PRX       0.00      0.00      0.00         1\n",
            "    ARGM-TMP       0.43      0.20      0.27        61\n",
            "\n",
            "    accuracy                           0.63      2910\n",
            "   macro avg       0.19      0.08      0.09      2910\n",
            "weighted avg       0.56      0.63      0.54      2910\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
        "\n",
        "print(\"Accuracy when used logistic regression model\",accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOJI2uajx_uf",
        "outputId": "52eb6558-b093-49ee-9b0a-0f4392fe48c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy when used logistic regression model 0.6257731958762887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Instead of using the logistic regression or any other classifier we can make use of neural networks for this task.\n",
        "\n",
        "### SRL using Neural Nets"
      ],
      "metadata": {
        "id": "le-x-RtzF0bT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def encode_labels(data):\n",
        "    le = LabelEncoder()\n",
        "\n",
        "    le.fit(data)\n",
        "\n",
        "    encoded_data = le.transform(data)\n",
        "\n",
        "    uniq_labels = list(le.classes_)\n",
        "\n",
        "    return encoded_data, uniq_labels, le\n",
        "\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "data['srl'] , classes , label_encoder = encode_labels(data['srl'])\n",
        "\n",
        "x_data = data.drop(['srl']\n",
        "y_data = data['srl']\n",
        "X_train, X_test, y_train, y_test = train_test_split(, axis=1), y_data , test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train shape :\", X_train.shape, y_train.shape)\n",
        "print(\"Test shape :\", X_test.shape, y_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "g6CV4-72R-DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def concat(x_data , y_data):\n",
        "  return pd.concat([x_data , y_data] , axis = 1)\n",
        "\n",
        "\n",
        "data_train = concat(X_train , y_train)\n",
        "data_test = concat(X_test , y_test)"
      ],
      "metadata": {
        "id": "Iqj-No1pXY3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7TAZyBKjXom8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data as data_utils\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self , data):\n",
        "    redundant_cols = ['Label', 'chunk', 'postposition', 'head-POS', 'dependency-head', 'dependency', 'srl', 'predicate']\n",
        "    #dropping all the unnecessary columns from the file\n",
        "    x = data.drop(redundant_cols,axis = 1)\n",
        "\n",
        "    self.emb = x\n",
        "    #convert the above obtained data into tensor form\n",
        "\n",
        "    self.emb = torch.Tensor(np.array(self.emb))\n",
        "    self.label  = torch.Tensor(data['srl'].values)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.emb)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    x_data = self.emb[index]\n",
        "    y_data = self.label[index]\n",
        "\n",
        "    return x_data , y_data\n"
      ],
      "metadata": {
        "id": "XL5U1ETsXnX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(data_train)\n",
        "test_dataset = CustomDataset(data_test)"
      ],
      "metadata": {
        "id": "0VcgrLiHa20v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}